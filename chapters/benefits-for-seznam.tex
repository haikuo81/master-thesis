\chapter{Benefits for Seznam.cz}

In the chapter ``\nameref{chapter:seznam-nowadays}" I~described how the developers are working today, what do they have to do and how the administrators are managing the machines. What is the motivation to switch to a solution based on Docker and Kubernetes and how to spread this new idea around? Obviously, apart from all the problems we identified before, there also have to be certain key benefits for both the developers and the administrators, otherwise it wouldn’t make sense to use it.

The biggest benefit I~see as a developer is that when an environment is created and deployed in the production environment, the developers can still access it easily. That is something I~miss a lot nowadays. The administrators prepare the virtual machine in the production using their Salt \cite{salt} prescriptions and then install packages from the developers. The developers are building and testing packages on their own virtual machines they create. There can be differences in many things from the network settings to different source list and different versions of libraries. It is also difficult to maintain virtual machines for building and testing for developers who could spend that time coding instead.

Docker solves those problems. Developer knows which packages in which version he needs, so he creates a Dockerfile with it. His image will be built from a base image provided by administrators where all the necessary settings are done and the same image will be used both in the production and in the testing environment. 

Docker also solves problems with library versions. Typical example may be one virtual machine where one service is running which consists of many packages and many smaller micro services. Each of this micro service is maintained by a different developer from the same team. When one of them changes somethings and wants to upgrade his micro service but he depends on a newer library, all other micro services will have to be updated as well. But with Docker, he just pushes the new image that will be updated in pod and no one else intervention is needed.

For the administrators the deployment will be easier as well. The developer defines the whole environment in a single image, so they just have to start it. The problem will be with debugging issues that occur in operation, because nowadays they can connect to any server and use debug tools they want and know. With Docker images in Kubernetes they first have to find the right container so they can attach to it, but if that image was created from scratch, no tools are provided there. In the beginning of our Kubernetes experience we should probably create all images from a base Debian image tailored to our needs so the administrators can use the same tools that they are used to. Then in the future we can move to more lightweight solutions.

Another inconvenience that the Kubernetes solution will solve is the secrets and configuration distribution. When the product manager wants a configuration change, for example setting a lower bound of a delivery score, the developer currently has to repack the application and issue a request ticket. The administrator then stops traffic to one server, installs the new version and restarts the application. After confirming that everything is alright, he can move on with the rest of the servers. With Kubernetes the developer will simply update the configuration, generate secret, push it to Git and send a merge request to the administrator. When the administrator accepts it, he updates the secret in the Kubernetes cluster and starts rolling update (or just sends signal to container, if the application supports configuration reload when running). Also SSL certificates can be stored in the Kubernetes cluster for development and production.

With Kubernetes the developers don’t need to maintain virtual machines for testing anymore. The administrators start two (or even more) instances of the Kubernetes cluster in the production and in the testing environment. The same pods, secrets and other resources will be deployed to those clusters.

Economic benefit is also that fewer servers is needed because they will be used more effectively. We can scale applications fast and more adaptively. Traffic will be monitored and examined and there surely be services that have minimal traffic in night so their number can be reduced dynamically.

The idea for the future not so far away is to use the same cluster which means the same machines in production delivery (services such as homepage and others) and for internal tasks like counting signals of webpages, machine learning of our algorithms and so more. If we group all machines in the data centre to one cluster and define proper policies for pod preference and priority, we can use the whole potential of this cluster at night and still have sufficient availability for users who access our services at the same time. This is the future goal were we are heading for.
